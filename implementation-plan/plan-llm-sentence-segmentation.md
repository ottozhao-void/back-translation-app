# LLM Platform & Intelligent Sentence Segmentation - Implementation Plan

## Overview

æœ¬æ–‡æ¡£æè¿°äº†ä¸€ä¸ª**é€šç”¨ LLM è°ƒç”¨å¹³å°**çš„å®ç°è®¡åˆ’ï¼Œä»¥åŠåŸºäºæ­¤å¹³å°çš„ç¬¬ä¸€ä¸ªåŠŸèƒ½ï¼šæ™ºèƒ½åˆ†å¥ã€‚

**æ ¸å¿ƒè®¾è®¡ç†å¿µ**ï¼š
1. **ç”¨æˆ·å¯é…ç½®** - ç”¨æˆ·å¯è‡ªå®šä¹‰ Base URL + API Keyï¼Œç³»ç»ŸåŠ¨æ€è·å–å¯ç”¨æ¨¡å‹
2. **ä»»åŠ¡æ— å…³** - å¹³å°åªè´Ÿè´£è°ƒç”¨ LLMï¼Œä¸åŒä»»åŠ¡åªéœ€æ›´æ¢ prompt
3. **å¯æ‰©å±•** - æœªæ¥çš„ç¿»è¯‘ã€è¯­ä¹‰å¯¹é½ç­‰åŠŸèƒ½éƒ½å¤ç”¨åŒä¸€æ¡†æ¶

---

## Part 1: é€šç”¨ LLM å¹³å°æ¡†æ¶

### 1.1 æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (React)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Settings UI          â”‚  Task-Specific UI                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ LLM Provider    â”‚  â”‚  â”‚ Segmentation    â”‚  â”‚ Translation     â”‚   â”‚
â”‚  â”‚ Configuration   â”‚  â”‚  â”‚ (åˆ†å¥)          â”‚  â”‚ (ç¿»è¯‘) [future] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚           â”‚           â”‚                   â”‚              â”‚
â”‚           â–¼           â”‚           â–¼                   â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              llmService.ts (Frontend Abstraction)            â”‚    â”‚
â”‚  â”‚  - executeTask(taskType, params) â†’ Promise<Result>           â”‚    â”‚
â”‚  â”‚  - getAvailableModels() â†’ Promise<Model[]>                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              â–¼                                       â”‚
â”‚                    Backend API Gateway                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  POST /api/llm/models     - è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨                  â”‚    â”‚
â”‚  â”‚  POST /api/llm/execute    - æ‰§è¡Œ LLM ä»»åŠ¡                    â”‚    â”‚
â”‚  â”‚  GET  /api/llm/config     - è·å–å½“å‰é…ç½®                      â”‚    â”‚
â”‚  â”‚  POST /api/llm/config     - ä¿å­˜é…ç½®                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                       â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              LLM Provider (OpenAI-Compatible API)            â”‚    â”‚
â”‚  â”‚  - User-configured Base URL + API Key                        â”‚    â”‚
â”‚  â”‚  - Supports: OpenAI, Gemini, Claude, Ollama, etc.            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`
**ä¸ºä»€ä¹ˆé€‰æ‹© OpenAI-Compatible API æ ¼å¼**ï¼š
1. å¤§å¤šæ•° LLM æä¾›å•†ï¼ˆåŒ…æ‹¬ Geminiã€Claudeã€Ollamaï¼‰éƒ½æ”¯æŒ OpenAI å…¼å®¹çš„ API æ ¼å¼
2. ç”¨æˆ·åªéœ€é…ç½® Base URL å’Œ API Keyï¼Œæ— éœ€å…³å¿ƒå…·ä½“å®ç°
3. ç»Ÿä¸€çš„æ¥å£ä½¿å¾—åˆ‡æ¢æ¨¡å‹å˜å¾—éå¸¸ç®€å•
`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`

---

### 1.2 æ•°æ®æ¨¡å‹

#### LLM é…ç½® (æ–°å¢åˆ° `types.ts`)

```typescript
// === LLM Platform Types ===

/**
 * LLM æä¾›å•†é…ç½®
 */
export interface LLMProviderConfig {
  id: string;                    // å”¯ä¸€æ ‡è¯†ï¼Œå¦‚ 'openai', 'gemini', 'custom-1'
  name: string;                  // æ˜¾ç¤ºåç§°ï¼Œå¦‚ 'OpenAI', 'Google Gemini'
  baseUrl: string;               // API Base URL
  apiKey: string;                // API Key (åŠ å¯†å­˜å‚¨)
  isEnabled: boolean;            // æ˜¯å¦å¯ç”¨
  models?: string[];             // ç¼“å­˜çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨
  lastFetched?: number;          // ä¸Šæ¬¡è·å–æ¨¡å‹åˆ—è¡¨çš„æ—¶é—´
}

/**
 * æ¨¡å‹å‚æ•°é…ç½®
 * ç”¨æˆ·å¯è°ƒæ•´çš„ LLM è°ƒç”¨å‚æ•°
 */
export interface LLMModelParams {
  temperature: number;           // æ¸©åº¦ (0-2)ï¼Œæ§åˆ¶éšæœºæ€§ï¼Œé»˜è®¤ 0
  topP: number;                  // Top-P é‡‡æ · (0-1)ï¼Œé»˜è®¤ 1
  maxTokens?: number;            // æœ€å¤§ç”Ÿæˆ token æ•°ï¼Œé»˜è®¤ä¸é™åˆ¶
  frequencyPenalty: number;      // é¢‘ç‡æƒ©ç½š (-2 to 2)ï¼Œé»˜è®¤ 0
  presencePenalty: number;       // å­˜åœ¨æƒ©ç½š (-2 to 2)ï¼Œé»˜è®¤ 0
  seed?: number;                 // éšæœºç§å­ï¼Œç”¨äºå¯å¤ç°ç»“æœ
}

/**
 * é»˜è®¤æ¨¡å‹å‚æ•°
 */
export const DEFAULT_MODEL_PARAMS: LLMModelParams = {
  temperature: 0,                // åˆ†å¥ç­‰ä»»åŠ¡éœ€è¦ç¡®å®šæ€§è¾“å‡º
  topP: 1,
  frequencyPenalty: 0,
  presencePenalty: 0,
};

/**
 * LLM æ¨¡å‹ä¿¡æ¯
 */
export interface LLMModel {
  id: string;                    // æ¨¡å‹ IDï¼Œå¦‚ 'gpt-4', 'gemini-2.0-flash'
  name: string;                  // æ˜¾ç¤ºåç§°
  providerId: string;            // æ‰€å±æä¾›å•† ID
  contextLength?: number;        // ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
  supportsJson?: boolean;        // æ˜¯å¦æ”¯æŒ JSON æ¨¡å¼
}

/**
 * LLM ä»»åŠ¡ç±»å‹
 */
export type LLMTaskType =
  | 'segment'           // åˆ†å¥
  | 'segment-align'     // è¯­ä¹‰å¯¹é½åˆ†å¥ (åŒæ—¶å¤„ç† EN+ZH)
  | 'translate'         // ç¿»è¯‘
  | 'score'             // è¯„åˆ†
  | 'custom';           // è‡ªå®šä¹‰ä»»åŠ¡

/**
 * LLM ä»»åŠ¡è¯·æ±‚
 */
export interface LLMTaskRequest {
  taskType: LLMTaskType;
  modelId: string;               // ä½¿ç”¨çš„æ¨¡å‹
  providerId: string;            // ä½¿ç”¨çš„æä¾›å•†
  params: Record<string, any>;   // ä»»åŠ¡å‚æ•°ï¼ˆç”±å…·ä½“ä»»åŠ¡å®šä¹‰ï¼‰
  modelParams?: Partial<LLMModelParams>;  // å¯é€‰çš„æ¨¡å‹å‚æ•°è¦†ç›–
}

/**
 * LLM ä»»åŠ¡å“åº”
 */
export interface LLMTaskResponse<T = any> {
  success: boolean;
  data?: T;
  error?: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

/**
 * LLM è®¾ç½® (æ‰©å±• AppSettings)
 */
export interface LLMSettings {
  providers: LLMProviderConfig[];
  defaultProvider?: string;      // é»˜è®¤æä¾›å•† ID
  defaultModel?: string;         // é»˜è®¤æ¨¡å‹ ID
  defaultParams: LLMModelParams; // å…¨å±€é»˜è®¤æ¨¡å‹å‚æ•°
  taskModels: {                  // æ¯ä¸ªä»»åŠ¡å¯å•ç‹¬æŒ‡å®šæ¨¡å‹
    [taskType in LLMTaskType]?: {
      providerId: string;
      modelId: string;
      params?: Partial<LLMModelParams>;  // ä»»åŠ¡çº§åˆ«å‚æ•°è¦†ç›–
    };
  };
}
```

#### æ‰©å±• AppSettings

```typescript
export interface AppSettings {
  autoSave: {
    enabled: boolean;
    delay: number;
  };
  llmThreshold: number;
  hotkeys: { [commandId: string]: string };
  practiceGranularity: 'sentence' | 'paragraph';

  // æ–°å¢ LLM è®¾ç½®
  llm: LLMSettings;
}
```

---

### 1.3 åç«¯ API è®¾è®¡

#### `/api/llm/models` - è·å–å¯ç”¨æ¨¡å‹

```typescript
// Request
POST /api/llm/models
{
  "baseUrl": "https://api.openai.com/v1",
  "apiKey": "sk-..."
}

// Response
{
  "success": true,
  "models": [
    { "id": "gpt-4", "name": "GPT-4" },
    { "id": "gpt-4-turbo", "name": "GPT-4 Turbo" },
    { "id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo" }
  ]
}
```

**å®ç°é€»è¾‘**ï¼š
```typescript
// è°ƒç”¨ OpenAI-compatible /models ç«¯ç‚¹
const response = await fetch(`${baseUrl}/models`, {
  headers: { 'Authorization': `Bearer ${apiKey}` }
});
const data = await response.json();
return data.data.map(m => ({ id: m.id, name: m.id }));
```

#### `/api/llm/execute` - æ‰§è¡Œ LLM ä»»åŠ¡

```typescript
// Request
POST /api/llm/execute
{
  "taskType": "segment",
  "providerId": "openai",
  "modelId": "gpt-4",
  "params": {
    "text": "Hello world. How are you?",
    "language": "en"
  }
}

// Response
{
  "success": true,
  "data": {
    "segments": ["Hello world.", "How are you?"]
  },
  "usage": {
    "promptTokens": 50,
    "completionTokens": 20,
    "totalTokens": 70
  }
}
```

**æ ¸å¿ƒå®ç°**ï¼š
```typescript
async function executeLLMTask(request: LLMTaskRequest): Promise<LLMTaskResponse> {
  const { taskType, providerId, modelId, params, modelParams } = request;

  // 1. è·å–æä¾›å•†é…ç½®
  const provider = getProviderConfig(providerId);

  // 2. è·å–ä»»åŠ¡å¯¹åº”çš„ system prompt
  const systemPrompt = getTaskPrompt(taskType, params);

  // 3. æ„å»ºç”¨æˆ·æ¶ˆæ¯
  const userMessage = buildUserMessage(taskType, params);

  // 4. åˆå¹¶æ¨¡å‹å‚æ•° (é»˜è®¤ < ä»»åŠ¡çº§åˆ« < è¯·æ±‚çº§åˆ«)
  const settings = getLLMSettings();
  const taskSettings = settings.taskModels[taskType];
  const finalParams: LLMModelParams = {
    ...DEFAULT_MODEL_PARAMS,
    ...settings.defaultParams,
    ...(taskSettings?.params || {}),
    ...(modelParams || {})
  };

  // 5. è°ƒç”¨ OpenAI-compatible API
  const response = await fetch(`${provider.baseUrl}/chat/completions`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${provider.apiKey}`
    },
    body: JSON.stringify({
      model: modelId,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage }
      ],
      response_format: { type: 'json_object' },
      // åº”ç”¨æ¨¡å‹å‚æ•°
      temperature: finalParams.temperature,
      top_p: finalParams.topP,
      max_tokens: finalParams.maxTokens,
      frequency_penalty: finalParams.frequencyPenalty,
      presence_penalty: finalParams.presencePenalty,
      seed: finalParams.seed
    })
  });

  // 6. è§£æå“åº”
  const data = await response.json();
  const content = JSON.parse(data.choices[0].message.content);

  return {
    success: true,
    data: content,
    usage: data.usage
  };
}
```

---

### 1.4 ä»»åŠ¡ Prompt æ³¨å†Œç³»ç»Ÿ

**æ–°æ–‡ä»¶**: `server/llm/prompts.ts`

```typescript
/**
 * LLM ä»»åŠ¡ Prompt æ³¨å†Œè¡¨
 * æ¯ä¸ªä»»åŠ¡ç±»å‹å®šä¹‰ï¼šç³»ç»Ÿæç¤ºè¯ + ç”¨æˆ·æ¶ˆæ¯æ„å»ºå™¨ + å“åº”è§£æå™¨
 */

export interface TaskPromptConfig {
  systemPrompt: string | ((params: any) => string);
  buildUserMessage: (params: any) => string;
  parseResponse: (raw: any) => any;
}

export const TASK_PROMPTS: Record<string, TaskPromptConfig> = {

  // ============ åˆ†å¥ä»»åŠ¡ ============
  segment: {
    systemPrompt: (params) => `
You are a precise text segmentation assistant. Split the following ${params.language === 'en' ? 'English' : 'Chinese'} text into individual sentences.

Rules:
1. Keep abbreviations intact (Mr., Dr., U.S., etc.)
2. Keep decimal numbers intact (3.14, 2.0, etc.)
3. Keep quoted speech as single units when appropriate
4. Preserve the original text exactly - do not translate or modify
5. Return a JSON object: { "segments": ["sentence1", "sentence2", ...] }
`,
    buildUserMessage: (params) => params.text,
    parseResponse: (raw) => ({ segments: raw.segments || [] })
  },

  // ============ è¯­ä¹‰å¯¹é½åˆ†å¥ä»»åŠ¡ ============
  'segment-align': {
    systemPrompt: `
You are a bilingual text alignment assistant. Given parallel English and Chinese texts, split them into semantically aligned sentence pairs.

Rules:
1. Each pair should contain semantically equivalent content
2. Handle 1:N and N:1 mappings (one sentence in one language may correspond to multiple in the other)
3. Preserve original text exactly
4. Return JSON: { "pairs": [{ "en": "...", "zh": "..." }, ...] }

If alignment is ambiguous, prefer keeping related content together rather than splitting.
`,
    buildUserMessage: (params) => `
English text:
${params.enText}

Chinese text:
${params.zhText}
`,
    parseResponse: (raw) => ({ pairs: raw.pairs || [] })
  },

  // ============ ç¿»è¯‘ä»»åŠ¡ (é¢„ç•™) ============
  translate: {
    systemPrompt: (params) => `
You are a professional translator. Translate the following text from ${params.from} to ${params.to}.
Maintain the original meaning, tone, and style.
Return JSON: { "translation": "..." }
`,
    buildUserMessage: (params) => params.text,
    parseResponse: (raw) => ({ translation: raw.translation || '' })
  },

  // ============ è¯„åˆ†ä»»åŠ¡ (é¢„ç•™) ============
  score: {
    systemPrompt: `
You are a translation quality assessor. Compare the user's translation with the reference and provide:
1. A score from 0-100
2. Specific feedback on accuracy, fluency, and style
3. Suggested improvements

Return JSON: { "score": number, "feedback": "...", "suggestions": ["..."] }
`,
    buildUserMessage: (params) => `
Original: ${params.original}
Reference: ${params.reference}
User's translation: ${params.userTranslation}
`,
    parseResponse: (raw) => ({
      score: raw.score || 0,
      feedback: raw.feedback || '',
      suggestions: raw.suggestions || []
    })
  }
};
```

`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`
**Prompt æ³¨å†Œç³»ç»Ÿçš„ä¼˜åŠ¿**ï¼š
1. **é›†ä¸­ç®¡ç†** - æ‰€æœ‰ prompt åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œæ˜“äºç»´æŠ¤å’Œä¼˜åŒ–
2. **ç±»å‹å®‰å…¨** - æ¯ä¸ªä»»åŠ¡å®šä¹‰è¾“å…¥è¾“å‡ºæ ¼å¼
3. **å¯æ‰©å±•** - æ·»åŠ æ–°ä»»åŠ¡åªéœ€æ³¨å†Œæ–°çš„ prompt é…ç½®
`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`

---

### 1.5 Settings UI æ‰©å±•

**ä¿®æ”¹æ–‡ä»¶**: `components/SettingsModal.tsx`

æ–°å¢ **"AI Models"** è®¾ç½®æ ‡ç­¾é¡µï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Settings                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â—‹ General      â”‚  AI Model Providers                               â”‚
â”‚  â—‹ Hotkeys      â”‚                                                   â”‚
â”‚  â— AI Models    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                 â”‚  â”‚ âœ“ OpenAI                           [Edit]   â”‚  â”‚
â”‚                 â”‚  â”‚   https://api.openai.com/v1                 â”‚  â”‚
â”‚                 â”‚  â”‚   Models: gpt-4, gpt-3.5-turbo              â”‚  â”‚
â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                 â”‚  â”‚ â—‹ Google Gemini                    [Edit]   â”‚  â”‚
â”‚                 â”‚  â”‚   https://generativelanguage.googleapis.com â”‚  â”‚
â”‚                 â”‚  â”‚   Models: gemini-2.0-flash, gemini-pro      â”‚  â”‚
â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  [+ Add Provider]                                 â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  Default Model for Tasks:                         â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  Segmentation:    [gpt-4 â–¼]                       â”‚
â”‚                 â”‚  Translation:     [gpt-4 â–¼]                       â”‚
â”‚                 â”‚  Scoring:         [gpt-3.5-turbo â–¼]               â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  Model Parameters (Global Defaults):              â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  Temperature      [====â—‹â”â”â”â”â”â”â”â”â”] 0.0            â”‚
â”‚                 â”‚  (Lower = more deterministic)                     â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  Top P            [â”â”â”â”â”â”â”â”â”â”â”â”â—‹] 1.0             â”‚
â”‚                 â”‚  (Nucleus sampling threshold)                     â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  Max Tokens       [        ] (empty = no limit)   â”‚
â”‚                 â”‚                                                   â”‚
â”‚                 â”‚  â–¼ Advanced Parameters                            â”‚
â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                 â”‚  â”‚ Frequency Penalty  [â”â”â”â”â”â—‹â”â”â”â”â”] 0.0        â”‚  â”‚
â”‚                 â”‚  â”‚ Presence Penalty   [â”â”â”â”â”â—‹â”â”â”â”â”] 0.0        â”‚  â”‚
â”‚                 â”‚  â”‚ Seed               [        ] (optional)    â”‚  â”‚
â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Provider ç¼–è¾‘å¯¹è¯æ¡†**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Edit Provider                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Name:     [OpenAI                    ]     â”‚
â”‚                                             â”‚
â”‚  Base URL: [https://api.openai.com/v1 ]     â”‚
â”‚                                             â”‚
â”‚  API Key:  [sk-â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢   ] ğŸ‘  â”‚
â”‚                                             â”‚
â”‚  [Fetch Models]                             â”‚
â”‚                                             â”‚
â”‚  Available Models:                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ â˜‘ gpt-4                             â”‚    â”‚
â”‚  â”‚ â˜‘ gpt-4-turbo                       â”‚    â”‚
â”‚  â”‚ â˜‘ gpt-3.5-turbo                     â”‚    â”‚
â”‚  â”‚ â˜ dall-e-3 (image model)            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                             â”‚
â”‚            [Cancel]  [Save]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Part 2: æ™ºèƒ½åˆ†å¥åŠŸèƒ½

åŸºäºä¸Šè¿°å¹³å°æ¡†æ¶ï¼Œæ™ºèƒ½åˆ†å¥æˆä¸ºç¬¬ä¸€ä¸ªå…·ä½“å®ç°çš„åŠŸèƒ½ã€‚

### 2.1 åŠŸèƒ½æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INPUT     â”‚ â”€â”€â–¶ â”‚  SEGMENT    â”‚ â”€â”€â–¶ â”‚   ALIGN     â”‚ â”€â”€â–¶ â”‚   SAVE      â”‚
â”‚  (Raw Text) â”‚     â”‚  (LLM Call) â”‚     â”‚  (User Fix) â”‚     â”‚  (Import)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ llmService.executeTask â”‚
              â”‚ taskType: 'segment'    â”‚
              â”‚ or 'segment-align'     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ä¸¤ç§åˆ†å¥æ¨¡å¼

#### æ¨¡å¼ A: ç‹¬ç«‹åˆ†å¥ (`segment`)
- åˆ†åˆ«å¯¹ EN å’Œ ZH æ–‡æœ¬è°ƒç”¨ LLM
- å„è‡ªè¿”å›å¥å­æ•°ç»„
- ç”¨æˆ·æ‰‹åŠ¨å¯¹é½

```typescript
// å¹¶è¡Œè°ƒç”¨ä¸¤æ¬¡
const [enResult, zhResult] = await Promise.all([
  llmService.executeTask('segment', { text: enText, language: 'en' }),
  llmService.executeTask('segment', { text: zhText, language: 'zh' })
]);
```

#### æ¨¡å¼ B: è¯­ä¹‰å¯¹é½åˆ†å¥ (`segment-align`)
- åŒæ—¶å°† EN å’Œ ZH æ–‡æœ¬é€å…¥ LLM
- LLM è¿”å›å·²å¯¹é½çš„å¥å¯¹
- æ›´æ™ºèƒ½ï¼Œä½† token æ¶ˆè€—æ›´é«˜

```typescript
// å•æ¬¡è°ƒç”¨ï¼ŒåŒæ—¶å¤„ç†
const result = await llmService.executeTask('segment-align', {
  enText,
  zhText
});
// result.pairs = [{ en: "Hello.", zh: "ä½ å¥½ã€‚" }, ...]
```

### 2.3 AlignmentEditor ç»„ä»¶

```typescript
interface AlignmentEditorProps {
  initialPairs: Array<{ en: string; zh: string }>;
  mode: 'independent' | 'semantic';  // æ˜¾ç¤ºä¸åŒçš„æ“ä½œæç¤º
  onSave: (pairs: Array<{ en: string; zh: string }>) => void;
  onCancel: () => void;
}
```

**æ“ä½œåŠŸèƒ½**ï¼š
- **Insert Gap** - åœ¨æŸä¸€ä¾§æ’å…¥ç©ºè¡Œï¼Œæ¨ç§»åç»­å†…å®¹
- **Remove Gap** - åˆ é™¤ç©ºè¡Œ
- **Merge Up** - ä¸ä¸Šä¸€è¡Œåˆå¹¶
- **Split** - åœ¨å…‰æ ‡å¤„æ‹†åˆ†ä¸ºä¸¤è¡Œ
- **Edit** - ç›´æ¥ç¼–è¾‘æ–‡æœ¬å†…å®¹

---

## Part 3: æ–‡ä»¶ç»“æ„

### æ–°å¢æ–‡ä»¶

```
back-translation-app/
â”œâ”€â”€ server/
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ index.ts              # LLM æœåŠ¡å…¥å£
â”‚       â”œâ”€â”€ prompts.ts            # Prompt æ³¨å†Œè¡¨
â”‚       â”œâ”€â”€ executor.ts           # ä»»åŠ¡æ‰§è¡Œå™¨
â”‚       â””â”€â”€ providers.ts          # æä¾›å•†ç®¡ç†
â”œâ”€â”€ services/
â”‚   â””â”€â”€ llmService.ts             # å‰ç«¯ LLM æœåŠ¡å°è£…
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â”œâ”€â”€ AIModelsTab.tsx       # AI æ¨¡å‹è®¾ç½®æ ‡ç­¾é¡µ
â”‚   â”‚   â””â”€â”€ ProviderEditModal.tsx # æä¾›å•†ç¼–è¾‘å¯¹è¯æ¡†
â”‚   â””â”€â”€ sentence-mode/
â”‚       â””â”€â”€ AlignmentEditor.tsx   # å¯¹é½ç¼–è¾‘å™¨
â””â”€â”€ types.ts                      # æ–°å¢ LLM ç›¸å…³ç±»å‹
```

### ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|----------|
| `types.ts` | æ–°å¢ LLM ç±»å‹å®šä¹‰ |
| `vite.config.ts` | æ·»åŠ  `/api/llm/*` è·¯ç”± |
| `server.js` | é•œåƒæ·»åŠ  `/api/llm/*` è·¯ç”± |
| `components/SettingsModal.tsx` | æ·»åŠ  "AI Models" æ ‡ç­¾é¡µ |
| `components/sentence-mode/ImportModal.tsx` | é›†æˆåˆ†å¥æµç¨‹ |

---

## Part 4: å®ç°é˜¶æ®µ

### Phase 1: ç±»å‹å®šä¹‰ä¸æ•°æ®ç»“æ„ âœ… COMPLETED

**ç›®æ ‡**: å»ºç«‹ LLM å¹³å°çš„ç±»å‹åŸºç¡€

**ä¿®æ”¹æ–‡ä»¶**:
- `types.ts`

**ä»»åŠ¡æ¸…å•**:
- [x] 1.1 å®šä¹‰ `LLMProviderConfig` æ¥å£ï¼ˆæä¾›å•†é…ç½®ï¼‰
- [x] 1.2 å®šä¹‰ `LLMModelParams` æ¥å£ï¼ˆæ¨¡å‹å‚æ•°ï¼štemperatureã€topP ç­‰ï¼‰
- [x] 1.3 å®šä¹‰ `DEFAULT_MODEL_PARAMS` å¸¸é‡
- [x] 1.4 å®šä¹‰ `LLMModel` æ¥å£ï¼ˆæ¨¡å‹ä¿¡æ¯ï¼‰
- [x] 1.5 å®šä¹‰ `LLMTaskType` ç±»å‹ï¼ˆä»»åŠ¡ç±»å‹æšä¸¾ï¼‰
- [x] 1.6 å®šä¹‰ `LLMTaskRequest` å’Œ `LLMTaskResponse` æ¥å£
- [x] 1.7 å®šä¹‰ `LLMSettings` æ¥å£
- [x] 1.8 æ‰©å±• `AppSettings` æ¥å£ï¼Œæ·»åŠ  `llm: LLMSettings` å­—æ®µ

**éªŒæ”¶æ ‡å‡†**: âœ… TypeScript ç¼–è¯‘é€šè¿‡ï¼Œç±»å‹å®šä¹‰å®Œæ•´

---

### Phase 2: åç«¯ API åŸºç¡€è®¾æ–½ âœ… COMPLETED

**ç›®æ ‡**: å®ç° LLM è°ƒç”¨çš„åç«¯ä»£ç†å±‚

**æ–°å¢æ–‡ä»¶**:
- `server/llm/index.ts` - LLM æœåŠ¡å…¥å£
- `server/llm/prompts.ts` - Prompt æ³¨å†Œè¡¨
- `server/llm/executor.ts` - ä»»åŠ¡æ‰§è¡Œå™¨
- `server/llm/providers.ts` - æä¾›å•†ç®¡ç†

**ä¿®æ”¹æ–‡ä»¶**:
- `vite.config.ts` - æ·»åŠ å¼€å‘ç¯å¢ƒ API è·¯ç”±
- `server.js` - æ·»åŠ ç”Ÿäº§ç¯å¢ƒ API è·¯ç”±

**ä»»åŠ¡æ¸…å•**:
- [x] 2.1 åˆ›å»º `server/llm/` ç›®å½•ç»“æ„
- [x] 2.2 å®ç° `providers.ts` - æä¾›å•†é…ç½®çš„è¯»å–/ä¿å­˜
  - [x] `getProviderConfig(providerId)` - è·å–å•ä¸ªæä¾›å•†é…ç½®
  - [x] `getAllProviders()` - è·å–æ‰€æœ‰æä¾›å•†
  - [x] `saveProviderConfig(config)` - ä¿å­˜æä¾›å•†é…ç½®
  - [x] `deleteProvider(providerId)` - åˆ é™¤æä¾›å•†
- [x] 2.3 å®ç° `prompts.ts` - Prompt æ³¨å†Œè¡¨
  - [x] å®šä¹‰ `TaskPromptConfig` æ¥å£
  - [x] æ³¨å†Œ `segment` ä»»åŠ¡ prompt
  - [x] æ³¨å†Œ `segment-align` ä»»åŠ¡ prompt
  - [x] æ³¨å†Œ `translate` ä»»åŠ¡ promptï¼ˆé¢„ç•™ï¼‰
  - [x] æ³¨å†Œ `score` ä»»åŠ¡ promptï¼ˆé¢„ç•™ï¼‰
- [x] 2.4 å®ç° `executor.ts` - æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
  - [x] `executeLLMTask(request)` - æ‰§è¡Œ LLM ä»»åŠ¡
  - [x] æ¨¡å‹å‚æ•°åˆå¹¶é€»è¾‘ï¼ˆé»˜è®¤ < ä»»åŠ¡çº§åˆ« < è¯·æ±‚çº§åˆ«ï¼‰
  - [x] é”™è¯¯å¤„ç†å’Œ fallback é€»è¾‘
- [x] 2.5 å®ç° `index.ts` - API è·¯ç”±å¤„ç†å™¨
  - [x] `POST /api/llm/models` - è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
  - [x] `POST /api/llm/execute` - æ‰§è¡Œ LLM ä»»åŠ¡
  - [x] `GET /api/llm/config` - è·å– LLM é…ç½®
  - [x] `POST /api/llm/config` - ä¿å­˜ LLM é…ç½®
- [x] 2.6 åœ¨ `vite.config.ts` ä¸­é›†æˆ API è·¯ç”±
- [x] 2.7 åœ¨ `server.js` ä¸­é•œåƒ API è·¯ç”±
- [x] 2.8 åˆ›å»º `data/llm-config.json` é…ç½®æ–‡ä»¶ï¼ˆåŠ å…¥ .gitignoreï¼‰

**éªŒæ”¶æ ‡å‡†**: âœ… API è·¯ç”±å·²å®ç°ï¼Œå¯é€šè¿‡ curl æµ‹è¯•

---

### Phase 3: å‰ç«¯æœåŠ¡å±‚ âœ… COMPLETED

**ç›®æ ‡**: å°è£…å‰ç«¯ LLM è°ƒç”¨æ¥å£

**æ–°å¢æ–‡ä»¶**:
- `services/llmService.ts`

**ä»»åŠ¡æ¸…å•**:
- [x] 3.1 å®ç° `fetchModels(baseUrl, apiKey)` - è·å–æ¨¡å‹åˆ—è¡¨
- [x] 3.2 å®ç° `executeTask(taskType, params, options?)` - æ‰§è¡Œä»»åŠ¡
- [x] 3.3 å®ç° `getConfig()` - è·å–å½“å‰ LLM é…ç½®
- [x] 3.4 å®ç° `saveConfig(config)` - ä¿å­˜ LLM é…ç½®
- [x] 3.5 å®ç° `segmentText(text, language)` - åˆ†å¥ä¾¿æ·æ–¹æ³•
- [x] 3.6 å®ç° `segmentAndAlign(enText, zhText)` - è¯­ä¹‰å¯¹é½åˆ†å¥ä¾¿æ·æ–¹æ³•
- [x] 3.7 æ·»åŠ é”™è¯¯å¤„ç†å’Œ fallback åˆ° regex çš„é€»è¾‘

**éªŒæ”¶æ ‡å‡†**: âœ… å‰ç«¯å¯è°ƒç”¨ `llmService.segmentText()` å¹¶è·å¾—ç»“æœ

---

### Phase 4: Settings UI - æä¾›å•†ç®¡ç† âœ… COMPLETED

**ç›®æ ‡**: ç”¨æˆ·å¯åœ¨è®¾ç½®ä¸­æ·»åŠ /ç¼–è¾‘ LLM æä¾›å•†

**æ–°å¢æ–‡ä»¶**:
- `components/settings/AIModelsTab.tsx` - AI æ¨¡å‹è®¾ç½®æ ‡ç­¾é¡µ
- `components/settings/ProviderEditModal.tsx` - æä¾›å•†ç¼–è¾‘å¯¹è¯æ¡†

**ä¿®æ”¹æ–‡ä»¶**:
- `components/SettingsModal.tsx` - æ·»åŠ  "AI Models" æ ‡ç­¾é¡µå…¥å£

**ä»»åŠ¡æ¸…å•**:
- [x] 4.1 åˆ›å»º `components/settings/` ç›®å½•
- [x] 4.2 å®ç° `ProviderEditModal.tsx`
  - [x] åç§°è¾“å…¥æ¡†
  - [x] Base URL è¾“å…¥æ¡†
  - [x] API Key è¾“å…¥æ¡†ï¼ˆå¸¦æ˜¾ç¤º/éšè—åˆ‡æ¢ï¼‰
  - [x] "Fetch Models" æŒ‰é’®
  - [x] æ¨¡å‹åˆ—è¡¨å±•ç¤ºï¼ˆå¯å‹¾é€‰å¯ç”¨/ç¦ç”¨ï¼‰
  - [x] ä¿å­˜/å–æ¶ˆæŒ‰é’®
- [x] 4.3 å®ç° `AIModelsTab.tsx`
  - [x] æä¾›å•†åˆ—è¡¨å±•ç¤º
  - [x] æ·»åŠ æä¾›å•†æŒ‰é’®
  - [x] ç¼–è¾‘/åˆ é™¤æä¾›å•†
  - [x] é»˜è®¤ä»»åŠ¡æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
- [x] 4.4 ä¿®æ”¹ `SettingsModal.tsx`
  - [x] æ·»åŠ  "AI Models" ä¾§è¾¹æ é¡¹
  - [x] æ·»åŠ  AI å›¾æ ‡ (SparklesIcon)
  - [x] æ¡ä»¶æ¸²æŸ“ `AIModelsTab` ç»„ä»¶

**éªŒæ”¶æ ‡å‡†**: âœ…
- ç”¨æˆ·å¯æ·»åŠ æ–°çš„ LLM æä¾›å•†
- ç‚¹å‡» "Fetch Models" å¯è·å–æ¨¡å‹åˆ—è¡¨
- é…ç½®ä¿å­˜ååˆ·æ–°é¡µé¢ä»ä¿ç•™

---

### Phase 5: Settings UI - æ¨¡å‹å‚æ•°é…ç½® âœ… COMPLETED

**ç›®æ ‡**: ç”¨æˆ·å¯è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆtemperature ç­‰ï¼‰

**ä¿®æ”¹æ–‡ä»¶**:
- `components/settings/AIModelsTab.tsx`

**ä»»åŠ¡æ¸…å•**:
- [x] 5.1 æ·»åŠ  "Model Parameters" åŒºåŸŸ
- [x] 5.2 å®ç° Temperature æ»‘å— (0-2)
- [x] 5.3 å®ç° Top P æ»‘å— (0-1)
- [x] 5.4 å®ç° Max Tokens è¾“å…¥æ¡†
- [x] 5.5 æ·»åŠ  "Advanced Parameters" æŠ˜å åŒºåŸŸ
  - [x] Frequency Penalty æ»‘å— (-2 to 2)
  - [x] Presence Penalty æ»‘å— (-2 to 2)
  - [x] Seed è¾“å…¥æ¡†
- [x] 5.6 å®ç°ä»»åŠ¡çº§åˆ«å‚æ•°è¦†ç›– UIï¼ˆTask-Specific Models ä¸‹æ‹‰æ¡†ï¼‰
- [x] 5.7 ä¿å­˜å‚æ•°åˆ°é…ç½®

**éªŒæ”¶æ ‡å‡†**: âœ…
- è°ƒæ•´å‚æ•°åæ‰§è¡Œä»»åŠ¡ï¼Œåç«¯æ”¶åˆ°æ­£ç¡®çš„å‚æ•°å€¼
- å‚æ•°ä¿å­˜ååˆ·æ–°é¡µé¢ä»ä¿ç•™

---

### Phase 6: å¯¹é½ç¼–è¾‘å™¨ç»„ä»¶ âœ… COMPLETED

**ç›®æ ‡**: åˆ›å»ºç”¨äºæ‰‹åŠ¨è°ƒæ•´å¥å­å¯¹é½çš„ç¼–è¾‘å™¨

**æ–°å¢æ–‡ä»¶**:
- `components/sentence-mode/AlignmentEditor.tsx`
- `utils/alignmentHelpers.ts` - å¯¹é½æ“ä½œè¾…åŠ©å‡½æ•°

**ä»»åŠ¡æ¸…å•**:
- [x] 6.1 å®ç° `alignmentHelpers.ts`
  - [x] `insertGapSimple(pairs, index, side)` - æ’å…¥ç©ºè¡Œ
  - [x] `removeGap(pairs, index, side)` - åˆ é™¤ç©ºè¡Œ
  - [x] `mergeUp(pairs, index, side)` - ä¸ä¸Šä¸€è¡Œåˆå¹¶
  - [x] `splitAt(pairs, index, side, charPos)` - åœ¨æŒ‡å®šä½ç½®æ‹†åˆ†
  - [x] `updateText(pairs, index, side, newText)` - æ›´æ–°æ–‡æœ¬
  - [x] `cleanEmptyPairs(pairs)` - æ¸…ç†ç©ºå¯¹
  - [x] `getAlignmentStats(pairs)` - è·å–å¯¹é½ç»Ÿè®¡
- [x] 6.2 å®ç° `AlignmentEditor.tsx` åŸºç¡€å¸ƒå±€
  - [x] åŒæ å¸ƒå±€ï¼ˆEnglish | ä¸­æ–‡ï¼‰
  - [x] å¥å­æ•°é‡ç»Ÿè®¡æ˜¾ç¤º
  - [x] åŒ¹é…/ä¸åŒ¹é…çŠ¶æ€æŒ‡ç¤ºå™¨
- [x] 6.3 å®ç°å•è¡Œç»„ä»¶ `SegmentRow`
  - [x] å¯ç¼–è¾‘æ–‡æœ¬åŒºåŸŸï¼ˆç‚¹å‡»ç¼–è¾‘ï¼Œè‡ªåŠ¨è°ƒæ•´é«˜åº¦ï¼‰
  - [x] Insert Gap æŒ‰é’® (â†“)
  - [x] Remove Gap æŒ‰é’® (Ã—) - ä»…ç©ºè¡Œæ˜¾ç¤º
  - [x] Merge Up æŒ‰é’® (â†‘)
  - [x] Ctrl+Enter æ‹†åˆ†åŠŸèƒ½
- [x] 6.4 å®ç°åŒæ­¥æ»šåŠ¨ï¼ˆå¯å¼€å…³ï¼‰
- [x] 6.5 å®ç°åº•éƒ¨æ“ä½œæ 
  - [x] Cancel æŒ‰é’®
  - [x] Import æŒ‰é’®ï¼ˆæ˜¾ç¤ºå°†å¯¼å…¥çš„å¥å¯¹æ•°é‡ï¼‰
- [x] 6.6 æ·»åŠ é”®ç›˜å¿«æ·é”®æ”¯æŒï¼ˆEscape å…³é—­ï¼ŒCtrl+Enter æ‹†åˆ†ï¼‰

**éªŒæ”¶æ ‡å‡†**: âœ…
- å¯æ’å…¥/åˆ é™¤ç©ºè¡Œè°ƒæ•´å¯¹é½
- å¯åˆå¹¶ç›¸é‚»å¥å­
- æ˜¾ç¤ºæ­£ç¡®çš„å¥å¯¹æ•°é‡

---

### Phase 7: ImportModal é›†æˆ âœ… COMPLETED

**ç›®æ ‡**: å°† LLM åˆ†å¥å’Œå¯¹é½ç¼–è¾‘å™¨é›†æˆåˆ°å¯¼å…¥æµç¨‹

**ä¿®æ”¹æ–‡ä»¶**:
- `components/sentence-mode/ImportModal.tsx`

**ä»»åŠ¡æ¸…å•**:
- [x] 7.1 æ·»åŠ å¯¼å…¥æ­¥éª¤çŠ¶æ€ (`'input' | 'loading' | 'align' | 'importing'`)
- [x] 7.2 ä¿®æ”¹ Paragraph/Article æ¨¡å¼çš„å¤„ç†æµç¨‹
  - [x] ç‚¹å‡» "Next" åè°ƒç”¨ LLM åˆ†å¥
  - [x] æ˜¾ç¤ºåŠ è½½çŠ¶æ€ï¼ˆå¸¦ spinner å’Œæç¤ºæ–‡å­—ï¼‰
  - [x] åˆ†å¥å®Œæˆåè¿›å…¥å¯¹é½æ­¥éª¤
- [x] 7.3 é›†æˆ `AlignmentEditor` ç»„ä»¶
- [x] 7.4 å®ç°åˆ†å¥æ¨¡å¼é€‰æ‹©ï¼ˆç‹¬ç«‹åˆ†å¥ vs è¯­ä¹‰å¯¹é½ï¼‰
  - [x] Independent: åˆ†åˆ«å¯¹ EN/ZH è°ƒç”¨ LLM
  - [x] Semantic Align: å•æ¬¡è°ƒç”¨åŒæ—¶å¤„ç†åŒè¯­å¯¹é½
- [x] 7.5 æ·»åŠ  fallback é€»è¾‘
  - [x] LLM å¤±è´¥æ—¶å›é€€åˆ° regex
  - [x] æ˜¾ç¤ºè­¦å‘Šæç¤º "Using simple segmentation"
  - [x] æ—  LLM é…ç½®æ—¶è‡ªåŠ¨ä½¿ç”¨ regex
- [x] 7.6 å¤„ç†å¯¹é½ç¼–è¾‘å™¨çš„ä¿å­˜å›è°ƒ
- [x] 7.7 æ›´æ–° UI æ ·å¼ä»¥é€‚åº”å¤šæ­¥æµç¨‹
  - [x] Batch æ¨¡å¼ä¿æŒç›´æ¥ Import æŒ‰é’®
  - [x] Paragraph/Article æ¨¡å¼ä½¿ç”¨ Next â†’ æŒ‰é’®

**éªŒæ”¶æ ‡å‡†**: âœ…
- Paragraph/Article æ¨¡å¼ä½¿ç”¨ LLM åˆ†å¥
- åˆ†å¥ç»“æœè¿›å…¥å¯¹é½ç¼–è¾‘å™¨
- LLM å¤±è´¥æ—¶è‡ªåŠ¨å›é€€

---

### Phase 8: æµ‹è¯•ä¸é”™è¯¯å¤„ç† âœ… COMPLETED

**ç›®æ ‡**: ç¡®ä¿åŠŸèƒ½ç¨³å®šå¯é 

**ä»»åŠ¡æ¸…å•**:
- [x] 8.1 é”™è¯¯å¤„ç†å·²å†…ç½®äºå„å±‚
  - [x] executor.ts: API é”™è¯¯ã€ç½‘ç»œé”™è¯¯ã€JSON è§£æé”™è¯¯
  - [x] llmService.ts: è‡ªåŠ¨ fallback åˆ° regex
  - [x] ImportModal.tsx: æ˜¾ç¤ºè­¦å‘Šæç¤º
- [x] 8.2 é”™è¯¯åœºæ™¯è¦†ç›–
  - [x] API Key æ— æ•ˆ â†’ è¿”å› API error å¹¶ fallback
  - [x] ç½‘ç»œè¶…æ—¶ â†’ è¿”å› Network error å¹¶ fallback
  - [x] æ¨¡å‹ä¸å­˜åœ¨ â†’ è¿”å›é”™è¯¯ä¿¡æ¯
  - [x] JSON è§£æå¤±è´¥ â†’ è¿”å›è§£æé”™è¯¯
- [x] 8.3 è¾¹ç•Œæƒ…å†µå¤„ç†
  - [x] ç©ºæ–‡æœ¬ â†’ ç›´æ¥è¿”å›ç©ºç»“æœ
  - [x] æ—  LLM é…ç½® â†’ è‡ªåŠ¨ä½¿ç”¨ regex
- [x] 8.4 é”™è¯¯æç¤ºä¿¡æ¯æ¸…æ™°
  - [x] è­¦å‘Šç”¨é»„è‰²æ˜¾ç¤º
  - [x] é”™è¯¯ç”¨çº¢è‰²æ˜¾ç¤º
  - [x] æˆåŠŸç”¨ç»¿è‰²æ˜¾ç¤º
- [x] 8.5 Loading çŠ¶æ€åŠ¨ç”»å·²å®ç°
- [x] 8.6 ä»£ç å®¡æŸ¥å®Œæˆï¼Œæ— é—ç•™é—®é¢˜

**éªŒæ”¶æ ‡å‡†**: âœ…
- æ‰€æœ‰é”™è¯¯åœºæ™¯æœ‰åˆç†å¤„ç†
- é”™è¯¯ä¿¡æ¯æ¸…æ™°æ˜“æ‡‚
- æ— æœªå¤„ç†çš„å¼‚å¸¸

---

### Phase 9: æ–‡æ¡£ä¸æ”¶å°¾ âœ… COMPLETED

**ç›®æ ‡**: å®Œå–„æ–‡æ¡£ï¼Œæ¸…ç†ä»£ç 

**ä»»åŠ¡æ¸…å•**:
- [x] 9.1 æ›´æ–° CLAUDE.md æ·»åŠ  LLM å¹³å°ç›¸å…³è¯´æ˜
  - [x] æ·»åŠ  LLM Platform Architecture ç« èŠ‚
  - [x] æ·»åŠ  LLM API Endpoints åˆ—è¡¨
  - [x] æ›´æ–° Application Structure ç›®å½•æ ‘
- [x] 9.2 æ›´æ–°å®ç°è®¡åˆ’æ–‡æ¡£æ ‡è®°å·²å®Œæˆ
- [x] 9.3 ä»£ç å®¡æŸ¥ï¼šconsole.log å‡ä¸ºåˆç†çš„é”™è¯¯æ—¥å¿—
- [x] 9.4 TypeScript ç¼–è¯‘é€šè¿‡ï¼Œæ— ç±»å‹é”™è¯¯

**éªŒæ”¶æ ‡å‡†**: âœ… åŠŸèƒ½å®Œæ•´å¯ç”¨ï¼Œæ–‡æ¡£å®Œå–„

---

## Part 5: å¸¸è§ LLM æä¾›å•†é…ç½®å‚è€ƒ

| æä¾›å•† | Base URL | å¤‡æ³¨ |
|--------|----------|------|
| OpenAI | `https://api.openai.com/v1` | æ ‡å‡†æ ¼å¼ |
| Azure OpenAI | `https://{resource}.openai.azure.com/openai/deployments/{deployment}` | éœ€è¦é¢å¤– header |
| Google Gemini | `https://generativelanguage.googleapis.com/v1beta/openai` | OpenAI å…¼å®¹ç«¯ç‚¹ |
| Anthropic Claude | `https://api.anthropic.com/v1` | éœ€è¦é€‚é…å™¨ |
| Ollama (æœ¬åœ°) | `http://localhost:11434/v1` | å®Œå…¨å…¼å®¹ |
| OpenRouter | `https://openrouter.ai/api/v1` | å¤šæ¨¡å‹ä»£ç† |

---

## Part 6: å®‰å…¨è€ƒè™‘

1. **API Key å­˜å‚¨**:
   - å¼€å‘ç¯å¢ƒï¼šå­˜å‚¨åœ¨ `.env` æ–‡ä»¶
   - ç”Ÿäº§ç¯å¢ƒï¼šå»ºè®®ä½¿ç”¨åŠ å¯†å­˜å‚¨æˆ–ç¯å¢ƒå˜é‡

2. **API Key ä¸æš´éœ²åˆ°å‰ç«¯**:
   - æ‰€æœ‰ LLM è°ƒç”¨é€šè¿‡åç«¯ä»£ç†
   - å‰ç«¯åªä¼ é€’ providerIdï¼Œä¸ä¼  API Key

3. **é…ç½®æ–‡ä»¶**:
   - ç”¨æˆ·é…ç½®å­˜å‚¨åœ¨ `data/llm-config.json`
   - åŠ å…¥ `.gitignore` é˜²æ­¢æ³„éœ²

---

## æˆåŠŸæ ‡å‡†

1. **å¯é…ç½®æ€§**: ç”¨æˆ·å¯æ·»åŠ ä»»æ„ OpenAI-compatible æä¾›å•†
2. **é€šç”¨æ€§**: æ·»åŠ æ–°ä»»åŠ¡åªéœ€æ³¨å†Œ promptï¼Œæ— éœ€æ”¹åŠ¨æ¡†æ¶ä»£ç 
3. **å¯é æ€§**: LLM å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ° regex
4. **æ€§èƒ½**: åˆ†å¥å“åº”æ—¶é—´ < 5s
5. **æ˜“ç”¨æ€§**: å¯¹é½ç¼–è¾‘å™¨æ“ä½œç›´è§‚

---

*æ–‡æ¡£æ›´æ–°: 2026-02-06*
*ç‰ˆæœ¬: 2.0 - é€šç”¨ LLM å¹³å°æ¶æ„*
